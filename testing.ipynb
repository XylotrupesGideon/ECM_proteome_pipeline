{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrisome annotation pipeline \n",
    "by: B.Gideon Bergheim\n",
    "\n",
    "For this project I need to annotate the proteome data to classify then and assign ECM domains etc.\n",
    "\n",
    "First we import the needed packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SearchIO,Entrez,SeqIO,SeqFeature\n",
    "import Bio\n",
    "import subprocess\n",
    "import os\n",
    "import itertools\n",
    "import logging\n",
    "import unittest\n",
    "import xml\n",
    "import svgwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n",
    "fasta_file = \"test\"\n",
    "protein_ids= [\"XP_001636042.2\",\"A7SXG9.2\"]\n",
    "email = \"gideon.bergheim@cos.uni-heidelberg.de\"\n",
    "output_directory= \"./outputs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create a log file which logs the actions performed by the script so any run can be replicated more easily and debugging is easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=output_directory + '\\.log', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline creates a number of output files. Therefore new folders need to be created and multiple points. Therefore I use a helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_out_dir(path):\n",
    "    \"Creates a new directory if it does not exist already.\"\n",
    "    if not os.path.exists(path):\n",
    "        logging.info(\"Creating directory: \" + path)\n",
    "        os.makedirs(path)\n",
    "\n",
    "create_out_dir(output_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases we are given sequence IDs. To work with the sequences themselves we need to download them from the NCBI database. It is best to do this in batches so this helper function downloads a list of NCBI identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "def download_seq_records(id_list, user_email, output_directory=\"./outputs\"):\n",
    "    \"\"\"\n",
    "    Searches and downloads the genebank and fasta records of the given Accession numbers from NCBI using Entrez\n",
    "    Parameter:\n",
    "    ---------\n",
    "    id_list: list of strings\n",
    "        list of valid NCBI protein acession numbers.\n",
    "    user_email: string, valid email address\n",
    "        The email address send to Entrez/NCBI. This e-mail will be contacted in case the scripts violates the user guidelines.\n",
    "    output_directory: path\n",
    "        path to directory where the Sequences should be saved. default is \"./outputs\". \n",
    "    \"\"\"\n",
    "    Entrez.email = user_email\n",
    "    create_out_dir(output_directory+\"/sequences/genebank\")\n",
    "    create_out_dir(output_directory+\"/sequences/fasta\")\n",
    "    logging.info(\"Downloading {} sequences.\".format(len(id_list)))\n",
    "    with Entrez.efetch(db=\"protein\", id=\",\".join(id_list), rettype=\"gb\") as handle:\n",
    "        for seq_record in SeqIO.parse(handle,\"gb\"):\n",
    "            SeqIO.write(seq_record,\n",
    "                \"./outputs/sequences/genebank/{seq_record}.gb\".format(seq_record=seq_record.id),\n",
    "                \"gb\")\n",
    "            SeqIO.write(seq_record,\n",
    "                \"./outputs/sequences/fasta/{seq_record}.fasta\".format(seq_record=seq_record.id),\n",
    "                \"fasta\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local InterProScan (recommended)\n",
    "We are looking up a lot of domains therefore it is highly recommended to use a local version of InterProScan to annotate the domains.\n",
    "\n",
    "IPR is available for linux and can be run on Windows computers using a Linux Subsystem (WSL).\n",
    "\n",
    "1. **(if on Windows) Install the WSL**\n",
    "2. **Install Interproscan**\n",
    "\n",
    "    See [here](https://interproscan-docs.readthedocs.io/en/latest/InstallationRequirements.html) for instructions\n",
    "\n",
    "    At the time of writing the instructions were:\n",
    "    ```shell\n",
    "    #checking requirements versions\n",
    "    uname -a\n",
    "    perl -version\n",
    "    python3 --version\n",
    "    java -version\n",
    "\n",
    "    #downloading interproscan\n",
    "    mkdir my_interproscan\n",
    "    cd my_interproscan\n",
    "    wget https://ftp.ebi.ac.uk/pub/software/unix/iprscan/5/5.57-90.0/interproscan-5.57-90.0-64-bit.tar.gz\n",
    "    wget https://ftp.ebi.ac.uk/pub/software/unix/iprscan/5/5.57-90.0/interproscan-5.57-90.0-64-bit.tar.gz.md5\n",
    "    #checking if the download was completed\n",
    "    md5sum -c interproscan-5.57-90.0-64-bit.tar.gz.md5\n",
    "\n",
    "    #unpacking interproscan\n",
    "    tar -pxvzf interproscan-5.57-90.0-*-bit.tar.gz\n",
    "    cd interproscan-5.57-90.0\n",
    "\n",
    "    #setup\n",
    "    python3 initial_setup.py\n",
    "\n",
    "    #test\n",
    "    ./intersproscan.sh\n",
    "    ```\n",
    "\n",
    "3. **Run interproscan**\n",
    "\n",
    "    We want to run intersprscan on all fasta sequences. Therefore we run it in a loop:\n",
    "\n",
    "    ```shell\n",
    "    for file in [path to folder]\n",
    "    do\n",
    "        ./interproscan.sh -i $file -o $file.xml -f xml  -goterms -pa\n",
    "    done\n",
    "    ```\n",
    "    where:\n",
    "    -f xml => specifies xml output file\n",
    "    -goterms => activates go-term annotation\n",
    "    -pa => activates pathway annotation\n",
    "\n",
    "    e.g. for this analysis the command was:\n",
    "    ```shell\n",
    "    for file in /mnt/d/Data/programs/proteome_pipeline/outputs/sequences/fasta/*.fasta;\n",
    "    do \t./interproscan.sh -i $file -o $file.xml -f xml  -goterms -pa -cpu 10;\n",
    "    done;\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (alternative SLOW!) InterProScan Web API access\n",
    "In some cases the local InterProScan does not work or the computer is not powerful enough to run it efficiently. In that case it is possible to use the InterProScan Web API. However this is very slow and should only be used as a last resort and only if you are looking up a few proteins at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go trough list of protein ids in chunks of 30\n",
    "def iter_chunker(iterable,chunksize,fillvalue=None):\n",
    "    \"\"\"\n",
    "    Cuts an iterable into chunks and returns these \n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    iterable: iterable python object\n",
    "        object to be chunked\n",
    "    chunksize: int\n",
    "        size of the chunks\n",
    "    fillvalue: any\n",
    "        value to be used to fill up the list if it is not dividable by the chunk size\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    itertools.zip_longest generator contianing tuples with the chunked elements\n",
    "    \"\"\"\n",
    "    args = [iter(iterable)] * chunksize\n",
    "    return itertools.zip_longest(*args, fillvalue=fillvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_fasta_file(path_to_fasta):\n",
    "    \"\"\"Splits a large fasta file sinto multiple files of 30 sequences each.\"\"\"\n",
    "\n",
    "    create_out_dir(output_directory + \"/sequences/chunked\")\n",
    "    large_seq= SeqIO.parse(path_to_fasta,\"fasta\")\n",
    "    chunks = iter_chunker(large_seq,30,Bio.Seq.Seq(\"\")) \n",
    "    for i,chunk in enumerate(chunks):\n",
    "        chunk = filter(None, chunk) #removes the none values\n",
    "        SeqIO.write(chunk,output_directory + \"/sequences/chunked/chunk_{}.fasta\".format(i),\"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a given fasta file can be chunked in order to go on with the InterProScan Annotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_fasta_file(\"testfiles/all_sequence.fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunked list can then be used with the InterProScan web interface to download domain annotations. Each request to InterProScan will take a few minutes (~2 minutes) so running this function will take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipr_scan(email,seq_file_name,out_name,*ipr5_args,output_directory=\"./outputs\"):\n",
    "   \"\"\"\n",
    "   Performs an InterProScan domain search on the provided fasta sequences.\n",
    "\n",
    "   Parameter:\n",
    "   ----------\n",
    "   email: string, valid email address\n",
    "      The email address send to IPR/EMBL/EBI. This e-mail will be contacted in case the scripts violates the user guidelines.\n",
    "   seq_file_name: string\n",
    "      name of the fasta file without file extension (foo.fasta -> foo). this name will be used for the job title and the output file names\n",
    "   output_directory: path\n",
    "      path to the desired output directory, default = \"./outputs\"\n",
    "   \"\"\"\n",
    "   print(\"[INFO] This process will run for a few minutes min.\")\n",
    "   create_out_dir(output_directory + \"/ipr/\")\n",
    "   command = \"\"\"python .\\iprscan5.py ^\n",
    "      --email {email} ^\n",
    "      --sequence {filename} ^\n",
    "      --title ipr_{filename} ^\n",
    "      --outfile {output_directory}/ipr/{out_name}\"\"\".format(\n",
    "         email = email, \n",
    "         filename = seq_file_name,\n",
    "         output_directory = output_directory,\n",
    "         out_name = out_name)\n",
    "   for arg in ipr5_args:\n",
    "      command += \" ^\\n\\t\" + arg\n",
    "   logging.info(\"Running Interproscan with argument:\\n\\t{}\".format(command))\n",
    "   stout = subprocess.run(command)\n",
    "   logging.info(\"Returned: \" + str(stout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IPR results can now be extracted from the chunked result files into individual IPR results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_ipr_results(seq_file_name,output_directory=\"./outputs\"):\n",
    "   out_dir= output_directory + \"/ipr/individual\"\n",
    "   create_out_dir(out_dir)\n",
    "   \n",
    "   context = xml.etree.ElementTree.parse( \"{}/ipr/{}.xml.xml\".format(output_directory,seq_file_name))\n",
    "   root = context.getroot()\n",
    "   for child in root:\n",
    "      ref = child.find(\"xref\")\n",
    "      for elem in child:\n",
    "         if str(elem.tag).split(\"}\")[1]==\"xref\":\n",
    "            protein_id = elem.attrib[\"id\"]\n",
    "            logging.info(\"Splitting off InterProScan results for {}\".format(protein_id))\n",
    "            with open(out_dir + \"/\" + protein_id + \".xml\",\"wb\") as out:\n",
    "               out.write('''<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "               <protein-matches xmlns=\"http://www.ebi.ac.uk/interpro/resources/schemas/interproscan5\" interproscan-version=\"5.57-90.0\">\\n'''.encode())\n",
    "               out.write(xml.etree.ElementTree.tostring(child))\n",
    "               out.write('</protein-matches>'.encode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotating the sequence files\n",
    "The InterProScan Results can now be used to annotate the sequences. \n",
    "\n",
    "First we need to read the IPR result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ipr_result(protein_id):\n",
    "    \"\"\"\n",
    "    Looks up the InterProScan results for an individual protein ID.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    protein ID\n",
    "    Returns:\n",
    "    --------\n",
    "    Biopython SearchIO-interproscan object\n",
    "    \"\"\"\n",
    "    logging.info(\"Looking up InterProScan results for {}\".format(protein_id))\n",
    "    try:\n",
    "        ipr_res = SearchIO.read(\"./outputs/ipr/individual/{filename}.xml\".format(filename=protein_id), \"interproscan-xml\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"This protein Id was not found.\")\n",
    "        logging.warn(\"{} InterProScan results file not found.\".format(protein_id))\n",
    "        ipr_res = None\n",
    "    return ipr_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we extract the Information and create annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_SeqFeatures_from_ipr(protein_ID):\n",
    "    \"\"\"\n",
    "    Extracts the domain annotations from an interproscan result xml and created biopython SeqFeature Objects that contain the domain annotations.\n",
    "\n",
    "     Parameters:\n",
    "    -----------\n",
    "    protein_ID: str, valid NCBI domain\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    features: list of Biopython SeqFeature objects\n",
    "    \"\"\"\n",
    "    #check if ipr results exsits\n",
    "    if not os.path.exists(\"outputs\\ipr\\individual\\{}.xml\".format(protein_ID)):\n",
    "        raise FileNotFoundError(\"The InterProScan results for {} do not exist, there might be an error with the previous analysis or you have skipped a step.\".format(protein_ID))\n",
    "\n",
    "    ipr = extract_ipr_result(protein_ID)\n",
    "    features = []\n",
    "    for hit in ipr.hits:     \n",
    "        #extract interproscan info\n",
    "        ipr_id = \"\"\n",
    "        ipr_name = \"unitegrated\"\n",
    "        ipr_type = \"unitegrated\"\n",
    "        if len(hit.dbxrefs)>0:\n",
    "            ipr_id = hit.dbxrefs[0]\n",
    "            ipr_name = \"\"\n",
    "            ipr_type = \"\"\n",
    "\n",
    "        #extract location info\n",
    "        locations = []\n",
    "        for hsp in hit.hsps:\n",
    "            locations.append(SeqFeature.FeatureLocation(*hsp.query_range))\n",
    "        if len(locations)>1:\n",
    "            location = SeqFeature.CompoundLocation(locations)\n",
    "        else:\n",
    "            location = locations[0]\n",
    "\n",
    "        # create SeqFeature\n",
    "        feature = SeqFeature.SeqFeature(location,\n",
    "                            type = hit.attributes[\"Target\"],\n",
    "                            qualifiers = {\n",
    "                                \"Database\":hit.attributes[\"Target\"],\n",
    "                                \"ID\": hit.id,\n",
    "                                \"Name\" :hit.accession,\n",
    "                                \"InterPro_ID\" : ['<a href=\"http://www.ebi.ac.uk/interpro/entry/{ipr}\">{ipr}</a>'.format(ipr=ipr_id)],\n",
    "                                \"InterPro_Name\": ipr_name,\n",
    "                                \"InterPro_TYPE\": ipr_type\n",
    "                            }) \n",
    "\n",
    "        features.append(feature)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we add the annotations to the sequence file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPR_to_annotation(protein_ID):\n",
    "    \"\"\"\n",
    "    Transfers the annotations found using IPR onto a sequence file and saves it as a genebank file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    protein_ID: protein ID. this must match the name of the IPR result file and the sequence file name (either the genebank or the fasta file).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        seq = SeqIO.read(output_directory + \"/sequences/genebank/{}.gb\".format(protein_ID),\"gb\")\n",
    "    except FileNotFoundError:\n",
    "        try :\n",
    "            seq = SeqIO.read(output_directory + \"/sequences/fasta/{}.fasta\".format(protein_ID),\"fasta\")\n",
    "        except FileNotFoundError:\n",
    "            logging.error(\"No sequence file found for {}.\".format(protein_ID))\n",
    "            raise FileNotFoundError(\"No sequence file found for {}.\".format(protein_ID))\n",
    "\n",
    "    features = extract_SeqFeatures_from_ipr(protein_ID)\n",
    "    seq.features.extend(features)\n",
    "    SeqIO.write(seq,output_directory + \"/sequences/genebank/{}_ipr.gb\".format(protein_ID),\"gb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPR_to_annotation(\"A7SXG9.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the annotations we need to visualize them.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5509e0e082928827ee81f812b4dba753c34a778562047cde93b4cb41b91ee2d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
